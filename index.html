import requests
from bs4 import BeautifulSoup

# URLs das lojas
URLS = {
    "Amazon": "https://www.amazon.com.br/s?k=pc+gamer",
    "Mercado Livre": "https://lista.mercadolivre.com.br/pc-gamer"
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

def obter_precos(url):
    """ Faz scraping da loja e retorna uma lista de PCs e pre√ßos. """
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        produtos = []

        if "amazon" in url:
            items = soup.find_all("div", {"data-component-type": "s-search-result"})
            for item in items[:5]:  
                titulo = item.find("span", class_="a-text-normal")
                preco = item.find("span", class_="a-price-whole")
                if titulo and preco:
                    produtos.append((titulo.text.strip(), f"R${preco.text.strip()}"))

        elif "mercadolivre" in url:
            items = soup.find_all("div", class_="ui-search-result")
            for item in items[:5]:  
                titulo = item.find("h2", class_="ui-search-item__title")
                preco = item.find("span", class_="price-tag-fraction")
                if titulo and preco:
                    produtos.append((titulo.text.strip(), f"R${preco.text.strip()}"))

        return produtos

    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar {url}: {e}")
        return []

def buscar_todos():
    """ Busca os produtos de todas as lojas. """
    dados = []
    for loja, url in URLS.items():
        produtos = obter_precos(url)
        for nome, preco in produtos:
            dados.append([loja, nome, preco, url])
    return dados

if __name__ == "__main__":
    print(buscar_todos())